Day 4 â€“ Logs, Failures & Crash Loop Handling (SRE Fundamentals)
Overview

On Day 4, I learned how Site Reliability Engineers debug real production issues using logs and how they handle service failures safely.

This day focused on:

Understanding what logs are

Using journalctl to read systemd logs

Observing service behavior during failures

Identifying and stopping crash loops

Logs are the primary source of truth during incidents, and this day introduced how SREs rely on them instead of guesswork.

What Are Logs?

Logs are timestamped records of events generated by the system and services.

Logs help answer three critical SRE questions:

What happened?

When did it happen?

Why did it happen?

Without logs, debugging becomes guesswork.
With logs, debugging becomes systematic and reliable.

systemd Logs and journalctl

Since services are managed by systemd, their logs are stored in the system journal.

The main tool used to read these logs is:

journalctl


This command displays logs collected by systemd for the entire system.

Viewing Logs for a Specific Service

To view logs for a specific service (my custom service sre-app), I used:

journalctl -u sre-app


This shows:

Service start events

Service stop events

Errors and failures

Timestamps for each event

This provides historical insight into how the service behaved over time.

Following Logs in Real Time

To monitor logs as events happen, I used:

journalctl -u sre-app -f


The -f flag means follow, which displays new log entries in real time.

This is commonly used by SREs during live incidents to observe failures as they occur.

Simulating a Service Failure

To understand failure behavior, I intentionally misconfigured the service so it would fail immediately on startup.

This caused:

The service to crash

systemd to attempt automatic restarts

Repeated failure events to appear in logs

What Is a Crash Loop?

A crash loop occurs when:

A service crashes due to an error

systemd restarts it automatically

The same error occurs again

This cycle repeats continuously

Crash loops are dangerous because they:

Consume system resources

Hide the root cause

Can destabilize the system if left unchecked

Identifying a Crash Loop Using Logs

The crash loop was identified by observing logs that showed:

Repeated service start attempts

Immediate failures

Restart attempts occurring every few seconds

Increasing restart counters

Logs made the crash loop pattern obvious and undeniable.

Stopping the Crash Loop (Incident Control)

To stop the crash loop safely, I:

Stopped the service to prevent further restarts

Fixed the misconfiguration in the service file

Reloaded systemd to apply changes

Restarted the service in a healthy state

This mirrors real SRE incident handling procedures.

Why Auto-Restart Can Be Dangerous

Auto-restart is essential for reliability, but it must be used carefully.

If a service is fundamentally broken or misconfigured:

Auto-restart can cause infinite crash loops

System resources can be exhausted

Root causes can be obscured

SREs may temporarily disable auto-restart during investigation.

Key Concepts Learned

Logs are the primary debugging tool in production

journalctl is used to inspect systemd-managed services

Crash loops indicate deeper configuration or application issues

Auto-restart improves availability but requires safeguards

Incident response prioritizes stopping damage before fixing issues

Commands Practiced
journalctl -u sre-app
journalctl -u sre-app -f
systemctl status sre-app
systemctl stop sre-app
systemctl start sre-app
systemctl daemon-reload

What This Means for SRE

This day introduced real SRE incident-handling skills:

Debugging using evidence (logs)

Recognizing unhealthy service patterns

Preventing runaway failures

Restoring system stability safely

These practices are essential for keeping production systems reliable and available.
